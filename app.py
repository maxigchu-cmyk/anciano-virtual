import streamlit as st
import google.generativeai as genai

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(page_title="Anciano de Bolsillo 3.0", page_icon="üìñ")

# T√≠tulo e Identidad
st.title("üìñ Anciano de Bolsillo")
st.caption("Investigaci√≥n B√≠blica Avanzada ‚Ä¢ Gemini 3.0 Flash")

# --- CONEXI√ìN ---
api_key = st.secrets.get("GEMINI_API_KEY")

if api_key:
    try:
        genai.configure(api_key=api_key)
        
        # DEFINICI√ìN DEL MODELO 3.0
        model = genai.GenerativeModel('gemini-3-flash')
        
        # LA INSTRUCCI√ìN MAESTRA (Master Prompt)
        # Aqu√≠ definimos el comportamiento profundo del asistente
        MASTER_PROMPT = (
            "Eres un anciano de congregaci√≥n de los Testigos de Jehov√° con d√©cadas de experiencia. "
            "Tu objetivo es dar consuelo, gu√≠a y √°nimo basado exclusivamente en la Biblia y las publicaciones provistas por el esclavo fiel y discreto.\n\n"
            "REGLAS DE RESPUESTA:\n"
            "1. FUENTES: Usa la Biblia Traducci√≥n del Nuevo Mundo (2013) y citas de wol.jw.org (La Atalaya, Despertad, Libros, etc.).\n"
            "2. EMPAT√çA: Primero, valida los sentimientos del hermano. Usa frases como 'Es comprensible que te sientas as√≠' o 'La Biblia muestra que otros pasaron por lo mismo'.\n"
            "3. ESTRUCTURA:\n"
                "   a) Un texto b√≠blico clave explicado con cari√±o.\n"
                "   b) Una referencia espec√≠fica a una publicaci√≥n reciente o relevante de jw.org.\n"
                "   c) Una sugerencia pr√°ctica y sencilla para la semana.\n"
            "4. TONO: S√© humilde, equilibrado y evita ser dogm√°tico. No des opiniones personales, sino lo que dice la organizaci√≥n.\n"
            "5. INVESTIGACI√ìN: Si el tema es complejo, resume los puntos principales de la Biblioteca en L√≠nea."
        )

        # Manejo de historial
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        # Entrada de usuario
        if prompt := st.chat_input("¬øQu√© tema b√≠blico quieres investigar?"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("Consultando la Biblia y las publicaciones..."):
                    # Combinamos la instrucci√≥n maestra con la consulta
                    full_query = f"{MASTER_PROMPT}\n\nConsulta del hermano: {prompt}"
                    
                    response = model.generate_content(full_query)
                    
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})

    except Exception as e:
        st.error(f"Error de conexi√≥n: {e}")
