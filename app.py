import streamlit as st
import google.generativeai as genai

# --- 1. CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(
    page_title="Anciano de Bolsillo", 
    page_icon="üìñ", 
    layout="centered"
)

# Estilo personalizado para mejorar la lectura
st.markdown("""
    <style>
    .stChatMessage { border-radius: 15px; margin-bottom: 10px; }
    h1 { color: #4A90E2; }
    </style>
    """, unsafe_allow_html=True)

st.title("üìñ Anciano de Bolsillo")
st.subheader("Investigador de la Biblioteca en L√≠nea")
st.info("Este asistente busca en wol.jw.org para darte respuestas b√≠blicas precisas.")

# --- 2. CONEXI√ìN CON GEMINI ---
api_key = st.secrets.get("GEMINI_API_KEY")

if not api_key:
    st.error("üîë Error: No se encontr√≥ la API Key en los Secrets de Streamlit.")
    st.stop()

try:
    genai.configure(api_key=api_key)
    
    # Configuramos el modelo con b√∫squeda en tiempo real (Google Search Grounding)
    # Esto le permite navegar por la Biblioteca en L√≠nea
    model = genai.GenerativeModel(
        model_name='gemini-2.5-flash',
        tools=[{"google_search_retrieval": {}}] 
    )
    
    # Instrucciones de comportamiento
    instrucciones_sistema = (
        "Eres un anciano de congregaci√≥n experto en investigaci√≥n b√≠blica. "
        "Tu √∫nica fuente de autoridad es la Biblia (TNM 2013) y las publicaciones de los Testigos de Jehov√°. "
        "Cuando el usuario pregunte algo, DEBES buscar en wol.jw.org y jw.org.\n\n"
        "FORMA DE RESPONDER:\n"
        "1. Resumen detallado: Explica el tema de forma clara y amorosa.\n"
        "2. Textos b√≠blicos: Incluye siempre los textos clave citados en las publicaciones.\n"
        "3. Referencias exactas: Al final, haz una lista de FUENTES (ej: La Atalaya, Despertad, Libro 'Pastoreen', etc.).\n"
        "4. Tono: Siempre equilibrado, razonable y emp√°tico."
    )

except Exception as e:
    st.error(f"‚ùå Error al conectar con el cerebro de la IA: {e}")

# --- 3. MANEJO DEL CHAT ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial de mensajes
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 4. ENTRADA DE PREGUNTAS ---
if prompt := st.chat_input("¬øQu√© tema quieres investigar hoy?"):
    # Guardar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    #
