import streamlit as st
import google.generativeai as genai

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(page_title="Anciano de Bolsillo - Investigador", page_icon="üõ°Ô∏è")

st.title("üõ°Ô∏è Investigador de la Biblioteca")
st.caption("Conectado a la Biblioteca en L√≠nea Watchtower")

# 1. Recuperar API Key
api_key = st.secrets.get("GEMINI_API_KEY")

if not api_key:
    st.error("No se encontr√≥ la clave GEMINI_API_KEY en los Secrets.")
    st.stop()

# 2. Configurar el Modelo con B√∫squeda en Google (Grounding)
try:
    genai.configure(api_key=api_key)
    
    # Usamos las herramientas de b√∫squeda para que pueda "navegar" por la WOL
    # Nota: Si gemini-2.5-flash te funcion√≥, lo mantenemos. Si no, usa 'gemini-1.5-flash'
    model = genai.GenerativeModel(
        model_name='gemini-2.5-flash', 
        tools=[{"google_search_retrieval": {}}] # ESTO ACTIVA LA B√öSQUEDA REAL
    )
    
    # Instrucciones estrictas para la "personalidad" de b√∫squeda
    instrucciones_sistema = (
        "Eres un experto en investigaci√≥n de la BIBLIOTECA EN L√çNEA Watchtower (wol.jw.org). "
        "Tu misi√≥n es ayudar a un hermano a encontrar informaci√≥n exacta. "
        "Sigue siempre estos pasos:\n"
        "1. BUSCA: Usa la herramienta de b√∫squeda para encontrar art√≠culos en wol.jw.org o jw.org.\n"
        "2. INFORMACI√ìN COMPLETA: Extrae la informaci√≥n m√°s relevante sobre el tema.\n"
        "3. RESUMEN: Haz un resumen claro y f√°cil de entender.\n"
        "4. FUENTES: Al final de tu respuesta, haz una lista con las fuentes usadas "
        "(T√≠tulo de la publicaci√≥n, fecha, p√°rrafo o revista).\n"
        "5. TONO: S√© siempre humilde, espiritual y animador."
    )

except Exception as e:
    st.error(f"Error de configuraci√≥n: {e}")

# 3. Chat
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("¬øQu√© tema te gustar√≠a investigar hoy?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            # Enviamos el prompt junto con las instrucciones de b√∫squeda
            query_completa = f"{instrucciones_sistema}\n\nConsulta del usuario: {prompt}"
            
            # La IA decidir√° si necesita buscar en internet para responder
            response = model.generate_content(query_completa)
            
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            st.error(f"Hubo un error en la b√∫squeda: {e}")
